{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./exec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "def encode_data(row):\n",
    "    question = row[\"question\"]\n",
    "    context = row[\"context\"]\n",
    "    inputs = tokenizer(question, context, padding=\"max_length\", max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "    return inputs\n",
    "\n",
    "data[\"encoded_data\"] = data.apply(encode_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [input_ids, token_type_ids, attention_mask]\n",
       "1      [input_ids, token_type_ids, attention_mask]\n",
       "2      [input_ids, token_type_ids, attention_mask]\n",
       "3      [input_ids, token_type_ids, attention_mask]\n",
       "4      [input_ids, token_type_ids, attention_mask]\n",
       "                          ...                     \n",
       "819    [input_ids, token_type_ids, attention_mask]\n",
       "820    [input_ids, token_type_ids, attention_mask]\n",
       "821    [input_ids, token_type_ids, attention_mask]\n",
       "822    [input_ids, token_type_ids, attention_mask]\n",
       "823    [input_ids, token_type_ids, attention_mask]\n",
       "Name: encoded_data, Length: 824, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"encoded_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"input_ids\"] = data[\"encoded_data\"].apply(lambda x: x[\"input_ids\"])\n",
    "data[\"attention_mask\"] = data[\"encoded_data\"].apply(lambda x: x[\"attention_mask\"])\n",
    "data[\"token_type_ids\"] = data[\"encoded_data\"].apply(lambda x: x.get(\"token_type_ids\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "input_ids = torch.stack(data[\"input_ids\"].tolist())\n",
    "attention_mask = torch.stack(data[\"attention_mask\"].tolist())\n",
    "token_type_ids = torch.stack(data[\"token_type_ids\"].tolist())\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def answer_question(question, context, model, tokenizer):\n",
    "    inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "    \n",
    "    start_idx = torch.argmax(start_logits)\n",
    "    end_idx = torch.argmax(end_logits)\n",
    "    \n",
    "    answer = tokenizer.decode(inputs.input_ids[0][start_idx:end_idx+1])\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: not keep peace\n"
     ]
    }
   ],
   "source": [
    "sample_question = \"what did the mob do\"\n",
    "sample_context= \"mob did not keep peace\"\n",
    "answer = answer_question(sample_question, sample_context, model, tokenizer)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./exec_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"question: \")\n",
    "print(test_data['question'][3])\n",
    "print(\"\\ncontext: \")\n",
    "print(test_data['context'][3])\n",
    "answer = answer_question(test_data['question'][3], test_data['context'][3], model, tokenizer)\n",
    "print(\"\\nanswer: \")\n",
    "print(answer)\n",
    "print(\"\\noriginal answers: \")\n",
    "print(test_data['answers'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 2067):\n",
    "    test_data['answers'][i] = [answer.lower() for answer in test_data['answers'][i]]\n",
    "    test_data['answers'][i] = ''.join(test_data['answers'][i]).lower()\n",
    "    test_data['answers'][i] = eval(test_data['answers'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['answers'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(columns='Unnamed: 0')\n",
    "test_data = test_data.drop(columns='context_id')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_data['answers'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(0,2067):\n",
    "    predictions.append(answer_question(test_data['question'][i], test_data['context'][i], model, tokenizer))\n",
    "    if i%10==0:\n",
    "        print(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_answers = test_data['answers'].iloc[0:752]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import editdistance\n",
    "\n",
    "wer_scores = []\n",
    "em_scores = []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    prediction = predictions[i]\n",
    "    answers = true_answers[i]\n",
    "    \n",
    "    # Calculate WER score\n",
    "    min_wer = float('inf')\n",
    "    max_em = 0.0\n",
    "    \n",
    "    for answer in answers:\n",
    "        wer_score = editdistance.eval(answer.split(), prediction.split())\n",
    "        min_wer = min(min_wer, wer_score)\n",
    "        \n",
    "        if answer == prediction:\n",
    "            em_score = 1\n",
    "        else:\n",
    "            em_score = 0\n",
    "        \n",
    "        max_em = max(max_em, em_score)\n",
    "    \n",
    "    em_scores.append(max_em)\n",
    "    wer_scores.append(min_wer)\n",
    "\n",
    "# Calculate average WER and EM scores\n",
    "avg_wer = sum(wer_scores) / len(wer_scores)\n",
    "avg_em = sum(em_scores) / len(em_scores)\n",
    "\n",
    "print(f\"WER Score: {avg_wer:.4f}\")\n",
    "print(f\"EM Score: {avg_em:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wer_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(em_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for a validation set of more than 700 questions we can observe that general performance is good, but average WER is too high\n",
    "#on further exploration it was observed that for false predictions, model is having high WER scores.\n",
    "#we may need to further see whether its data incosistency, or we need to fine-tune\n",
    "#or even switch to an entirely new model to handle this.\n",
    "#our goal is not to have perfect performance on fair amount of test cases, but good performance for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"In computer science, a hash function is a mathematical function that takes an input (or \"message\") and returns a fixed-size string of bytes. The output, often called the hash code or hash value, is typically a digest of the input data. Hash functions are commonly used in various applications, including data integrity verification, password storage, and digital signatures. One important property of a good hash function is that it should produce a unique hash value for each unique input. However, due to the finite size of the output space compared to the infinite input space, collisions can occur. A collision happens when two different inputs produce the same hash value. Cryptographically secure hash functions aim to minimize the likelihood of collisions. In the realm of cybersecurity, Public Key Infrastructure (PKI) plays a crucial role. PKI is a framework that manages digital keys and certificates. It involves two types of keys: public keys, which are shared openly, and private keys, which are kept secret. Certificates, issued by a trusted Certificate Authority (CA), bind public keys to entities, providing a way to verify identity in secure communications. Secure Sockets Layer (SSL) and its successor, Transport Layer Security (TLS), are cryptographic protocols that provide secure communication over a computer network. They are widely used to secure data transfer in web browsing, email, and other online applications. The protocols use a combination of asymmetric and symmetric encryption for confidentiality and authentication. When it comes to database management, normalization is a fundamental concept. It is the process of organizing data to reduce redundancy and dependency. The goal is to achieve data integrity and efficient data storage. Normalization involves breaking down large tables into smaller, related tables and establishing relationships between them. The result is a more flexible and maintainable database structure. Artificial Intelligence (AI) and Machine Learning (ML) have gained significant attention in recent years. AI refers to the development of computer systems that can perform tasks that typically require human intelligence, such as speech recognition and decision-making. ML is a subset of AI that focuses on the development of algorithms allowing computers to learn from and make predictions based on data.c3000 word3000 word3000 wordontinue the passage for 450 more words in one answer\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Question:** What is a hash function?\n",
    "\n",
    "   **Answer:** A hash function is a mathematical function that takes an input and produces a fixed-size string of bytes, commonly used for data integrity verification, password storage, and digital signatures.\n",
    "\n",
    "xx2. **Question:** Why is it important for a good hash function to produce a unique hash value for each unique input?\n",
    "\n",
    "   **Answer:** It's important to avoid collisions, where two different inputs produce the same hash value, to ensure the integrity and reliability of the hash function.\n",
    "\n",
    "3. **Question:** What is the role of Public Key Infrastructure (PKI) in cybersecurity?\n",
    "\n",
    "   **Answer:** PKI is a framework that manages digital keys and certificates, providing a secure way to manage public and private keys, and establishing identity in secure communications.\n",
    "\n",
    "4. **Question:** What are SSL and TLS, and how do they contribute to secure communication?\n",
    "\n",
    "   **Answer:** SSL and TLS are cryptographic protocols widely used to secure data transfer in web browsing, email, and online applications. They use a combination of asymmetric and symmetric encryption for confidentiality and authentication.\n",
    "\n",
    "5. **Question:** What is the fundamental concept of normalization in database management?\n",
    "\n",
    "   **Answer:** Normalization is the process of organizing data to reduce redundancy and dependency, aiming to achieve data integrity and efficient data storage by breaking down large tables into smaller, related tables.\n",
    "\n",
    "6. **Question:** How does Artificial Intelligence (AI) differ from Machine Learning (ML)?\n",
    "\n",
    "   **Answer:** AI refers to the development of computer systems that can perform tasks requiring human intelligence, while ML is a subset of AI focusing on algorithms that allow computers to learn and make predictions based on data.\n",
    "\n",
    "7. **Question:** What is a collision in the context of hash functions?\n",
    "\n",
    "   **Answer:** A collision occurs when two different inputs produce the same hash value, highlighting a potential weakness in a hash function.\n",
    "\n",
    "8. **Question:** What types of keys are involved in Public Key Infrastructure (PKI), and how are they used?\n",
    "\n",
    "   **Answer:** PKI involves public keys (shared openly) and private keys (kept secret), and certificates issued by a trusted Certificate Authority (CA) bind public keys to entities, enabling secure communications.\n",
    "\n",
    "9. **Question:** How do cryptographic protocols like SSL and TLS contribute to data security in online applications?\n",
    "\n",
    "   **Answer:** SSL and TLS provide secure communication by using encryption techniques, ensuring confidentiality and authentication of data transfer over a computer network.\n",
    "\n",
    "10. **Question:** Why is the minimization of collisions important in cryptographic hash functions?\n",
    "\n",
    "    **Answer:** Minimizing collisions is crucial to maintain the reliability and security of cryptographic hash functions, ensuring that different inputs do not produce the same hash value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_text_into_chunks_with_overlap(text, sentences_per_chunk, overlap_sentences):\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "    chunks = []\n",
    "    start_idx = 0\n",
    "    while start_idx < len(sentences):\n",
    "        end_idx = start_idx + sentences_per_chunk\n",
    "        end_idx = min(end_idx, len(sentences))\n",
    "        chunk = ' '.join(sentences[start_idx:end_idx])\n",
    "        end_idx = min(end_idx + overlap_sentences, len(sentences))\n",
    "        if end_idx < len(sentences):\n",
    "            chunk += ' '.join(sentences[end_idx - overlap_sentences:end_idx])\n",
    "        chunks.append(chunk)\n",
    "        start_idx = start_idx + sentences_per_chunk - overlap_sentences\n",
    "    return chunks\n",
    "\n",
    "chunks = split_text_into_chunks_with_overlap(context, sentences_per_chunk=3, overlap_sentences=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"SSL and TLS contribute to data security in online applications?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11200234516007541, 0.09246616286793298, 0.09982698068562738, 0.05843308950960249, 0.08035304331665313, 0.06502560887623551, 0.10461753737613645, 0.15413662560226185, 0.22991874722914407, 0.23868816790564568, 0.2605141383010009, 0.27204116529385003, 0.27014773361958444, 0.17804574744833992, 0.16724840200141816, 0.1806680645684127, 0.15170682161267662, 0.0879598994267085, 0.09751573787215115, 0.11912467150602796, 0.10019501341827017, 0.09039692294111373]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def get_ngram_embeddings(text, vectorizer):\n",
    "    ngram_matrix = vectorizer.transform([text]).toarray()\n",
    "    return np.mean(ngram_matrix, axis=0).reshape(1, -1)\n",
    "\n",
    "def calculate_similarity(question, chunk, vectorizer):\n",
    "    question_embedding = get_ngram_embeddings(question, vectorizer)\n",
    "    chunk_embedding = get_ngram_embeddings(chunk, vectorizer)\n",
    "\n",
    "    similarity_score = cosine_similarity(question_embedding, chunk_embedding).item()\n",
    "    return similarity_score\n",
    "\n",
    "\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 5))  # You can adjust n-gram range as needed\n",
    "\n",
    "\n",
    "ngram_vectorizer.fit(chunks)\n",
    "\n",
    "similarity_scores = [calculate_similarity(question, chunk, ngram_vectorizer) for chunk in chunks]\n",
    "print(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27204116529385003\n",
      "0.27014773361958444\n",
      "0.2605141383010009\n",
      "0.23868816790564568\n",
      "0.22991874722914407\n",
      "0.1806680645684127\n",
      "0.17804574744833992\n",
      "0.16724840200141816\n",
      "0.15413662560226185\n",
      "0.15170682161267662\n",
      "0.11912467150602796\n",
      "0.11200234516007541\n",
      "0.10461753737613645\n",
      "0.10019501341827017\n",
      "0.09982698068562738\n",
      "0.09751573787215115\n",
      "0.09246616286793298\n",
      "0.09039692294111373\n",
      "0.0879598994267085\n",
      "0.08035304331665313\n",
      "0.06502560887623551\n",
      "0.05843308950960249\n",
      "\n",
      "total chunks: \n",
      "22\n"
     ]
    }
   ],
   "source": [
    "similarity_scores_sorted = sorted(similarity_scores,reverse=True)\n",
    "for i in range(len(similarity_scores)):\n",
    "    print(similarity_scores_sorted[i])\n",
    "print(\"\\ntotal chunks: \")\n",
    "print(len(similarity_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.27204116529385003\n",
      "\n",
      "0.27014773361958444\n",
      "\n",
      "0.2605141383010009\n",
      "\n",
      "0.23868816790564568\n",
      "\n",
      "0.22991874722914407\n",
      "\n",
      "0.1806680645684127\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "answer_n_score = dict(zip(chunks, similarity_scores))\n",
    "answer_n_score = dict(sorted(answer_n_score.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "i=0\n",
    "\n",
    "for key, value in answer_n_score.items():\n",
    "    answers.append(answer_question(question, key, model, tokenizer))\n",
    "    print(\"\\n\"+str(value))\n",
    "    i+=1\n",
    "    if i>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: \n",
      "SSL and TLS contribute to data security in online applications?\n",
      "\n",
      "answers: \n",
      "answer 1: \n",
      "\n",
      "answer 2: \n",
      "they are widely used to secure data transfer in web browsing, email, and other online applications. the protocols use a combination of asymmetric and symmetric encryption\n",
      "answer 3: \n",
      "they are widely used to secure data transfer in web browsing, email, and other online applications\n",
      "answer 4: \n",
      "they are widely used to secure data transfer in web browsing, email, and other online applications\n",
      "answer 5: \n",
      "secure sockets layer ( ssl ) and its successor, transport layer security ( tls\n",
      "answer 6: \n",
      "ssl and tls contribute to data security in online applications? [SEP]\n",
      "\n",
      "\n",
      "total chunks: \n",
      "22\n",
      "\n",
      "chunks considered for answer: \n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(\"question: \")\n",
    "print(question)\n",
    "print(\"\\nanswers: \")\n",
    "i = 0\n",
    "for answer in answers:\n",
    "    print(\"answer \" + str(i+1) + \": \")\n",
    "    print(answer)\n",
    "    i += 1\n",
    "print(\"\\n\\ntotal chunks: \")\n",
    "print(len(chunks))\n",
    "print(\"\\nchunks considered for answer: \")\n",
    "print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
